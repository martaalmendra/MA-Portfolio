ungroup() %>%
filter(n_carriers > 1)
flights %>%
group_by(dest) %>%
summarize(n_carriers = n_distinct(carrier)) %>%
ungroup() %>%
filter(n_carriers > 1)
#Forecasting Methods - Week 3
library(fma)
library(fpp3)
#a
advsales_tsibble <- advsales %>%
as_tsibble()
#b
books_tsibble <- books %>%
as_tsibble()
#c
canadian_tsibble <- canadian %>%
as_tsibble()
#d
housing_tsibble <- housing %>%
as_tsibble() %>%
pivot_wider(id_cols = index, names_from = key)
#extra
housing_tsibble %>%
mutate(quarter = yearquarter(index)) %>%
as_tibble() %>%
select(-index) %>%
group_by(quarter) %>%
summarize(hstarts= sum(hstarts),
construction = sum(construction),
interest = mean(interest)) %>%
ungroup() %>%
tsibble(index = quarter)
#4
gafa_stock %>%
group_by(Symbol) %>%
filter(Close == max(Close)) %>%
ungroup() %>%
select(Symbol,Date, Close)
#5
tute1 <- read.csv("tute1.csv")
library(fpp3)
canadian_gas %>%
autoplot(volume) +
labs(
x = "Year" , y = "Gas production (billion cubic meters" ,
title = "Monthly Canadian gas production"
)
canadian_gas %>%
autoplot(Volume) +
labs(
x = "Year" , y = "Gas production (billion cubic meters" ,
title = "Monthly Canadian gas production"
)
View(aus_production)
aus_production %>%
autoplot("Tobacco")
aus_production %>%
autoplot(Tobacco)
View(ansett)
View(ansett)
ansett %>%
filter(Class = "Economy" | Airports = "MEL-SYD") %>%
ansett %>%
filter(Class = "Economy" | Airports = "MEL-SYD") %>%
ansett %>%
filter(Class == "Economy" | Airports == "MEL-SYD") %>%
autoplot(Passengers)
ansett %>%
filter(Class == "Economy" | Airports == "MEL-SYD") %>%
autoplot(Passengers)
ansett %>%
filter(Class == "Economy",Airports == "MEL-SYD") %>%
autoplot(Passengers)
aus_production %>%
autoplot(Tobacco) + theme_minimal()
ansett %>%
filter(Class == "Economy", Airports == "MEL-SYD") %>%
autoplot(Passengers) +
labs(title = "Economy passengers", subtitle="MEL-SYD")
pedestrian %>%
filter(Sensor == "Southern Cross Station") %>%
autoplot(logIp(Count)) +
labs(title = "Southern Cross Pedestrians")
pedestrian %>%
filter(Sensor == "Southern Cross Station") %>%
autoplot(Count) +
labs(title = "Southern Cross Pedestrians")
pedestrian %>%
filter(Sensor == "Southern Cross Station") %>%
autoplot(log1p(Count)) +
labs(title = "Southern Cross Pedestrians")
gas <- tail(aus_production, 5*4) %>% select(Gas)
gas %>%
autoplot(Gas) + labs(y = "Petajoules") + theme_minimal()
decomp <- gas %>%
model(decomp = classical_decomposition(Gas, type = "multiplicative")) %>%
components()
gas %>%
model(decomp = classical_decomposition(Gas, type = "multiplicative")) %>%
components()
decomp %>% autoplot()
as_tsibble(decomp) %>%
autoplot(season_adjust) +
labs(title = "Seasonally adjusted data" , y = "Petajoules")
mutate(Gas = if_else(Quarter == yearquarter("2010Q2"), Gas + 300, Gas)) %>%
model(decomp= classical_decomposition(Gas, type = "multiplicative")) %>%
components()
canadian_gas %>%
autoplot()
canadian_gas %>%
gg_subseries()
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_season()
remove.packages("ggplot2")
install.packages("C:/Users/Marta/Downloads/ggplot2_3.4.4.tar.gz", repos = NULL, type = "source")
canadian_gas %>%
gg_season()
install.packages("C:/Users/Marta/Downloads/ggplot2_3.4.4.tar.gz", repos = NULL, type = "source")
library(fpp3)
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_season()
canadian_gas %>%
gg_subseries()
canadian_gas %>%
gg_subseries()
canadian_gas %>%
gg_subseries()
canadian_gas %>%
gg_season()
global_economy %>%
filter(Country == "Australia") %>%
autoplot(Population)
library(fpp3)
global_economy %>%
filter(Country == "Australia") %>%
autoplot(Population)
global_economy %>%
filter(Country == "Australia") %>%
model(RW(Population ~ drift())) %>%
forecast(h = '10 years') %>%
autoplot(global_economy)
global_economy %>%
filter(Country == "Australia") %>%
autoplot(Population)
ibrary(bwght)
library(bwght)
library(wooldridge)
wooldridge
View(bwght)
View(HPRICE1)
View(hprice1)
cov(sqrft, price)
cov(sqrft,price)
hprice %>%
cov(sqrft,price)
View(hprice)
data(hprice, package='wooldridge')
attach(hprice)
data(hprice, package='wooldridge')
attach(hprice)
attach(hprice1)
cov(sqrft,price)
var(price)
source("~/.active-rstudio-document", echo=TRUE)
(b0hat <- mean(price) - b1hat*mean(sqrft))
library(wooldridge)
View(ceosal2)
data(ceosal2, package='wooldridge')
attach(ceosal2)
library(wooldridge)
library(fpp3)
#a)
fit <- us_change %>%
model(TSLM(Consumption ~ Income))
fit %>%
gg_tsresiduals()
#a)
fit <- us_change %>%
model(TSLM(Consumption ~ Income))
fit %>%
gg_tsresiduals()
model(TSLM(Consumption ~ Income))
#a)
fit <- us_change %>%
model(TSLM(Consumption ~ Income))
fit %>%
gg_tsresiduals()
fit <- us_change %>%
model(TSLM(Consumption ~ Income))
fit %>%
gg_tsresiduals()
fit %>%
gg_tsdisplay(.innov, plot_type = 'partial')
fit %>%
augment () %>%
gg_tsdisplay(.innov, plot_type = 'partial')
augment()
fit %>%
augment() %>%
fit %>%
augment()
augment(fit)
("C:/Users/Marta/Desktop/universidade/2nd year/Forecasting Methods/Forecast_Project")
library(fpp3)
library(lubridate)
library(urca)
## Setting a correct path
setwd("C:/Users/Marta/Desktop/universidade/2nd year/Forecasting Methods/Forecast_Project")
getwd()
## Importing data
eletric = read.csv('Electric_Production.csv')
View(eletric)
augment(best_mod) %>%
filter(.model=='sarima101111') %>%
features(.innov, ljung_box, lag = 36 )
best_mod <- eletric_training %>%
model(
sarima101111  = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,1)),
sarima201111 = ARIMA(log(amount_electric) ~ 0 + pdq(2,0,1) + PDQ(1,1,1)),
sarima101011 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,1)),
snaive = SNAIVE(log(amount_electric))
)
##Libraries to use
library(fpp3)
library(lubridate)
library(urca)
## Setting a correct path
setwd("C:/Users/Marta/Desktop/universidade/2nd year/Forecasting Methods/Forecast_Project")
getwd()
## Importing data
eletric = read.csv('Electric_Production.csv')
View(eletric)
## Data Transformation
#turning the dataset into a tsibble and initial adjustments
eletric_tsibble = eletric %>%
mutate(Month = yearmonth(DATE)) %>%
select(Month, amount_electric = IPG2211A2N) %>%
as_tsibble(index = Month)
View(eletric_tsibble)
## 1st Analysis - Plots
eletric_tsibble %>% gg_tsdisplay(amount_electric, plot_type = 'partial', lag_max = 36)
eletric_tsibble %>% gg_season()
#similar behaviors throughout the years, but with rising values
#high values in the beginning of the years
#drop in values from march to may
#with a following rising pattern in the summer
eletric_tsibble %>% autoplot(amount_electric)
#rising trend and seasonality present
eletric_tsibble %>% gg_subseries()
## Division of data into Train/Test sets
# training set - jan 1985 to dec 2015
eletric_training = eletric_tsibble %>%
filter(year(Month)<2016)
# test set - jan 2016 - jan 2018 (duration of 2 years)
eletric_test = eletric_tsibble %>%
filter(year(Month)>=2016)
## Variance analysis
# Slight increase in variance over time
eletric_training %>% autoplot(amount_electric)
# use of a logarithm to stabilize it
eletric_training %>% autoplot(log(amount_electric))
## Dickey-Fuller Test & Differencing
# Dickey-Fuller test on the original stabilized data
summary(ur.df(na.omit(log(eletric_training$amount_electric)), type = c("trend"), lags = 12))
#test-statistic (-0.9588) > critical values at all significance levels
#null hypothesis of the presence of a unit root cannot be rejected
#time series still not stationary - so we will apply a seasonal difference
### First Seasonal Difference ###
eletric_training_diff <- eletric_training %>%
mutate(first_dif = difference(log(amount_electric), 12))
# Dickey-Fuller test with first seasonal difference
summary(ur.df(na.omit(eletric_training_diff$first_dif), type = c("trend"), lags = 12))
# test-statistic (-6.433) < critical values at all significance levels
#null hypothesis of the presence of a unit root is rejected
#so now we can carry on with the forecast
# Visualize ACF and PACF
eletric_training_diff %>% gg_tsdisplay(first_dif, plot_type = 'partial')
## Model identification: Fit various possible SARIMA models
#ARIMA (p,d,q) (P,D,Q) - model combinations:
# p usually 1 due to spike in pacf
# d = 0 because we didn't do differencing
# q usually 1 due to spike acf
# P usually 1 due to spike at lag 12,24 in pacf
# D = 1 since we made one seasonal difference
# Q usually 1 due to spike at lag 12 in acf
fit <- eletric_training %>%
model(
sarima101111 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,1)),
sarima101110 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,0)),
sarima101010 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,0)),
sarima101011 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,1)),
sarima100010 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,0) + PDQ(0,1,0)),
sarima100110 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,0) + PDQ(1,1,0)),
sarima100111 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,0) + PDQ(1,1,1)),
sarima201111 = ARIMA(log(amount_electric) ~ 0 + pdq(2,0,1) + PDQ(1,1,1))
)
## Model Selection
#Information Criteria
fit %>%
glance()
#chose the 3 best models based on information criteria - lower AIC and BIC, to then compare with benchmark method
best_mod <- eletric_training %>%
model(
sarima101111  = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,1)),
sarima201111 = ARIMA(log(amount_electric) ~ 0 + pdq(2,0,1) + PDQ(1,1,1)),
sarima101011 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,1)),
snaive = SNAIVE(log(amount_electric))
)
#Residual Plots and Ljung-Box test for best models
#sarima101111
best_mod %>%
select(sarima101111) %>%
gg_tsresiduals() # not white noise - correlation
augment(best_mod) %>%
filter(.model=='sarima101111') %>%
features(.innov, ljung_box, lag = 36 )   # p-value < 0.05 - autocorrelation in residuals
#sarima201111
best_mod %>%
select(sarima201111) %>%
gg_tsresiduals() #white noise
augment(best_mod) %>%
filter(.model=='sarima201111') %>%
features(.innov, ljung_box, lag = 12 )   #no autocorrelation in the residuals
#sarima101011
best_mod %>%
select(sarima101011) %>%
gg_tsresiduals() # not white noise - correlation
augment(best_mod) %>%
filter(.model=='sarima101011') %>%
features(.innov, ljung_box, lag = 12 )   # p-value < 0.05 - autocorrelation in residuals
#Only sarima201111 passes the Ljung-Box test
##Forecasting
# Forecasting 24 months (2 years)
forecast_mods <- best_mod %>%
forecast(h = "24 months")
forecast_mods %>%
autoplot(eletric_test,level= NULL) +labs(y= 'amount_electric',
title = 'Electric Production Forecasts using Best Models')
## Accuracy of the models
accuracy_metrics <- forecast_mods %>%
accuracy(eletric_test)
print(accuracy_metrics)
#sarima201111 has lowest errors overall followed by the seasonal naive method and the sarima101011  - so we exclude sarima101111
## Final Model SARIMA(2,0,1)(1,1,1)
best_mod %>%
select(sarima201111) %>%
report()
## Final Forecast
best_mod %>%
select('sarima201111') %>%
forecast(h=24) %>%
autoplot(eletric_training) + labs(y='amount_electric',
title = 'Electric Production Final Forecast')
augment(best_mod) %>%
filter(.model=='sarima101111') %>%
features(.innov, ljung_box, lag = 36 )
augment(best_mod) %>%
filter(.model=='sarima101111') %>%
features(.innov, ljung_box, lag = 36)
augment(best_mod) %>%
filter(.model=='sarima201111') %>%
features(.innov, ljung_box, lag = 36 )
augment(best_mod) %>%
filter(.model=='sarima101011') %>%
features(.innov, ljung_box, lag = 36)
library(fpp3)
library(lubridate)
library(urca)
## Setting a correct path
setwd("C:/Users/Marta/Desktop/universidade/2nd year/Forecasting Methods/Forecast_Project")
getwd()
## Importing data
eletric = read.csv('Electric_Production.csv')
View(eletric)
## Data Transformation
#turning the dataset into a tsibble and initial adjustments
eletric_tsibble = eletric %>%
mutate(Month = yearmonth(DATE)) %>%
select(Month, amount_electric = IPG2211A2N) %>%
as_tsibble(index = Month)
View(eletric_tsibble)
## 1st Analysis - Plots
eletric_tsibble %>% gg_tsdisplay(amount_electric, plot_type = 'partial', lag_max = 36)
eletric_tsibble %>% gg_season()
#similar behaviors throughout the years, but with rising values
#high values in the beginning of the years
#drop in values from march to may
#with a following rising pattern in the summer
eletric_tsibble %>% autoplot(amount_electric)
#rising trend and seasonality present
eletric_tsibble %>% gg_subseries()
## Division of data into Train/Test sets
# training set - jan 1985 to dec 2015
eletric_training = eletric_tsibble %>%
filter(year(Month)<2016)
# test set - jan 2016 - jan 2018 (duration of 2 years)
eletric_test = eletric_tsibble %>%
filter(year(Month)>=2016)
## Variance analysis
# Slight increase in variance over time
eletric_training %>% autoplot(amount_electric)
# use of a logarithm to stabilize it
eletric_training %>% autoplot(log(amount_electric))
## Dickey-Fuller Test & Differencing
# Dickey-Fuller test on the original stabilized data
summary(ur.df(na.omit(log(eletric_training$amount_electric)), type = c("trend"), lags = 12))
#test-statistic (-0.9588) > critical values at all significance levels
#null hypothesis of the presence of a unit root cannot be rejected
#time series still not stationary - so we will apply a seasonal difference
### First Seasonal Difference ###
eletric_training_diff <- eletric_training %>%
mutate(first_dif = difference(log(amount_electric), 12))
# Dickey-Fuller test with first seasonal difference
summary(ur.df(na.omit(eletric_training_diff$first_dif), type = c("trend"), lags = 12))
# test-statistic (-6.433) < critical values at all significance levels
#null hypothesis of the presence of a unit root is rejected
#so now we can carry on with the forecast
# Visualize ACF and PACF
eletric_training_diff %>% gg_tsdisplay(first_dif, plot_type = 'partial')
## Model identification: Fit various possible SARIMA models
#ARIMA (p,d,q) (P,D,Q) - model combinations:
# p usually 1 due to spike in pacf
# d = 0 because we didn't do differencing
# q usually 1 due to spike acf
# P usually 1 due to spike at lag 12,24 in pacf
# D = 1 since we made one seasonal difference
# Q usually 1 due to spike at lag 12 in acf
fit <- eletric_training %>%
model(
sarima101111 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,1)),
sarima101110 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,0)),
sarima101010 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,0)),
sarima101011 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,1)),
sarima100010 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,0) + PDQ(0,1,0)),
sarima100110 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,0) + PDQ(1,1,0)),
sarima100111 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,0) + PDQ(1,1,1)),
sarima201111 = ARIMA(log(amount_electric) ~ 0 + pdq(2,0,1) + PDQ(1,1,1))
)
## Model Selection
#Information Criteria
fit %>%
glance()
#chose the 3 best models based on information criteria - lower AIC and BIC, to then compare with benchmark method
best_mod <- eletric_training %>%
model(
sarima101111  = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(1,1,1)),
sarima201111 = ARIMA(log(amount_electric) ~ 0 + pdq(2,0,1) + PDQ(1,1,1)),
sarima101011 = ARIMA(log(amount_electric) ~ 0 + pdq(1,0,1) + PDQ(0,1,1)),
snaive = SNAIVE(log(amount_electric))
)
#Residual Plots and Ljung-Box test for best models
#sarima101111
best_mod %>%
select(sarima101111) %>%
gg_tsresiduals() # not white noise - correlation
augment(best_mod) %>%
filter(.model=='sarima101111') %>%
features(.innov, ljung_box, lag = 36)   # p-value < 0.05 - autocorrelation in residuals
#sarima201111
best_mod %>%
select(sarima201111) %>%
gg_tsresiduals() #white noise
augment(best_mod) %>%
filter(.model=='sarima201111') %>%
features(.innov, ljung_box, lag = 36 ) #no autocorrelation in the residuals
#sarima101011
best_mod %>%
select(sarima101011) %>%
gg_tsresiduals() # not white noise - correlation
augment(best_mod) %>%
filter(.model=='sarima101011') %>%
features(.innov, ljung_box, lag = 36)   # p-value < 0.05 - autocorrelation in residuals
#Only sarima201111 passes the Ljung-Box test
##Forecasting
# Forecasting 24 months (2 years)
forecast_mods <- best_mod %>%
forecast(h = "24 months")
forecast_mods %>%
autoplot(eletric_test,level= NULL) +labs(y= 'amount_electric',
title = 'Electric Production Forecasts using Best Models')
## Accuracy of the models
accuracy_metrics <- forecast_mods %>%
accuracy(eletric_test)
print(accuracy_metrics)
#sarima201111 has lowest errors overall followed by the seasonal naive method and the sarima101011  - so we exclude sarima101111
## Final Model SARIMA(2,0,1)(1,1,1)
best_mod %>%
select(sarima201111) %>%
report()
## Final Forecast
best_mod %>%
select('sarima201111') %>%
forecast(h=24) %>%
autoplot(eletric_training) + labs(y='amount_electric',
title = 'Electric Production Final Forecast')
accuracy_metrics <- forecast_mods %>%
accuracy(eletric_test)
print(accuracy_metrics)
